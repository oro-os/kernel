#![no_std]

//! ser2mem is a serializer framework for `no_std` environments
//! that enables Oro bootloaders to transfer memory to the Oro kernel
//! prior to switching to the kernel's execution environment (namely,
//! before switching the memory map).
//!
//! Source structures are built up entirely on the stack by the bootloaders,
//! and then "serialized" to a location in memory linearly using a bootloader-
//! supplied page frame allocator (linearly, panicking on errors).
//!
//! During serialization, all iterators are expanded to contiguous
//! arrays of data, the base address and length of which are then written
//! to the original field as a slice (since slice fields are translated
//! to Iterator fields in the proxy objects generated by this crate) -
//! but instead of handing the currently-valid base address to
//! [core::slice::from_raw_parts], instead the _target_ (eventual) base
//! address is encoded.
//!
//! Normally this would be an _incredibly_ unsafe, undefined-behavior-invoking
//! thing to do in Rust. However, since the slice itself is only stored to
//! memory and never directly accessed prior to the execution of the
//! kernel, no undefined behavior is actually invoked. This can be guaranteed
//! due to the fact that the slices are only ever passed around within
//! the serializer implementation and never handed back to the user. The
//! user would have to go out of their way to re-cast the base pointer
//! to the structure and then reference them, which isn't something we
//! can prevent anyway.
//!
//! The net result is this:
//!
//! - Bootloaders need not allocate memory just to store arbitrary-length
//!   Oro data structures (e.g. memory maps) and do not have to write
//!   custom handling into the kernel itself.
//! - Nested and arbitrary length data structures are supported without
//!   hassle, including using iterators to map bootloader structures to
//!   Oro structures, without any allocations necessary.
//! - The kernel simply has to cast the root structure's base address
//!   to a `*const T` in order to use it; all pointers will Just Work,
//!   all data will be aligned correctly, and all representations are
//!   guaranteed to be well-formed.
//!
//! This isn't really a novel or particularly clever way of doing things;
//! it's just the fact that iterators are used and that all of this is
//! generated at compile time to clean off the boilerplate that is really
//! the unusual thing happening here. This is not dissimilar to bootloaders
//! allocating memory for themselves to hand info to the next boot stage.
//!
//! Please note that there are several types that are simply disallowed.
//! Most of them are due to the nature of `#[repr(C)]` and its safety,
//! such as not allowing Tuples or "fat pointers".

pub mod _detail;

use core::marker::PhantomData;

pub use oro_ser2mem_proc::Ser2Mem;

/// To be implemented by bootloaders in order to allocate linear
/// chunks of memory starting from the Oro boot protocol base address.
///
/// The first allocation should be at the address specified by the
/// configuration in `oro-boot`, aligned to the same alignment required
/// by the base config structure type (typically page aligned; check
/// the `#[repr(...)]` attribute to be sure).
///
/// # Safety
///
/// This allocator MUST halt the CPU if it runs out of memory, preferably
/// with an error message.
pub unsafe trait Allocator {
	/// Returns the next base address that would be allocated by the
	/// next call to `allocate()`.
	fn position(&self) -> u64;

	/// Allocate `sz` bytes of memory, directly (contiguously) after
	/// the memory allocated by the last call to `allocate()` - or,
	/// if this is the first call, at the boot address defined by
	/// `oro-boot`.
	///
	/// # Safety
	///
	/// This call MUST allocate memory at the specified location,
	/// and MUST halt if the allocate fails for some reason, preferably
	/// with an error message.
	///
	/// Corrollary, if this function returns, ser2mem will assume the
	/// allocation succeeded. Returning after an unsuccessful allocation
	/// will IMMEDIATELY invoke undefined behavior.
	unsafe fn allocate(&mut self, sz: u64);

	/// Aligns the next allocation to a specific boundary.
	///
	/// # Safety
	///
	/// See all safety considerations of `allocate()`.
	unsafe fn align(&mut self, alignment: u64) {
		debug_assert!(alignment > 0); // avoid DBZ in the modulo operation
		let unaligned = self.position() % alignment;
		if unaligned != 0 {
			let to_alloc = alignment - unaligned;
			self.allocate(to_alloc);
		}
	}
}

/// # Safety
///
/// Does some erotic dancing with pointers. Do not implement yourself;
/// the only valid way to implement this trait is to use `#[derive(Ser2Mem)]`.
pub unsafe trait Serialize {
	/// # Safety
	///
	/// Among other things (such as writing invalid slices to memory),
	/// `alloc.position()` must report an address that is aligned to
	/// `Self`'s alignment requirements prior to calling this function.
	/// This function will only align child elements prior to serializing
	/// them, but expects the caller to have done so beforehand.
	unsafe fn serialize<A>(self, alloc: &mut A)
	where
		A: Allocator;
}

/// Get the proxied type of a `Ser2Mem`-derived type.
/// The returned type is the type that should be populated
/// and subsequently serialized to memory.
#[macro_export]
macro_rules! Proxy {
	($ty:ty) => {
		<$ty as $crate::_detail::Proxied>::Proxy
	};
}

/// This is some black magic. Essentially, we have to emulate iterator types to silence
/// the Rust compiler's type checking in order to invoke the `Proxy!` macro to get the
/// anonymously generated struct type based on the boot information structs. It's a whole
/// deal. Luckily, this is the "ugliest" and "hackiest" part of the whole thing, and doing
/// it this way makes it so that we don't need to pollute the boot protocol namespace
/// with unhygienic procedural macros.
pub struct Fake<T>
where
	T: Sized + _detail::Serializable,
{
	pd: PhantomData<T>,
}

impl<T> Clone for Fake<T>
where
	T: Sized + _detail::Serializable,
{
	fn clone(&self) -> Self {
		panic!("do not actually construct or clone a Fake iterator!");
	}
}

impl<T> Iterator for Fake<T>
where
	T: Sized + _detail::Serializable,
{
	type Item = T;
	fn next(&mut self) -> Option<Self::Item> {
		panic!("do not actually iterate over a Fake iterator!");
	}
}

pub trait CloneIterator: Clone + Iterator {}
impl<T> CloneIterator for T where T: Clone + Iterator {}
